{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d8c264",
   "metadata": {},
   "source": [
    "# SPARC-P Digital Human Backend\n",
    "\n",
    "## 1.0 Introduction and System Goals\n",
    "This notebook implements the **Real-Time, Multi-Agent Backend** for SPARC-P on HiPerGator.\n",
    "\n",
    "### 1.1 Objectives\n",
    "1. **Conda Environment**: Use conda for package management (UF RC requirement)\n",
    "2. **Containerized Deployment**: Run Riva via Apptainer (Python backend uses conda)\n",
    "3. **Orchestration**: Use **LangGraph** to manage the multi-agent state machine\n",
    "4. **Audit Logging**: Immutable logging to `/blue` tier for compliance\n",
    "5. **API Exposure**: `POST /v1/chat` endpoint for Unity\n",
    "\n",
    "### 1.2 Environment Prerequisites\n",
    "- **Compute**: HiPerGator GPU Node (Persistent Service)\n",
    "- **Software**: Conda environment (sparc_backend), Apptainer for Riva\n",
    "- **Models**: Access to `/blue/jasondeanarnold/SPARCP/trained_models`\n",
    "\n",
    "![notebook 3 - section 1.png](images/notebook_3_-_section_1.png)\n",
    "\n",
    "Introduction and System Goals: This section defines the objectives for the real-time backend. It implements the Real-Time, Multi-Agent Backend on HiPerGator, utilizing conda environments for Python dependencies, Apptainer for Riva containerization, LangGraph for orchestration, and immutable audit logging to the /blue tier for compliance.\n",
    "\n",
    "**⚠️ Before running this notebook:**\n",
    "```bash\n",
    "module load conda\n",
    "conda activate /blue/jasondeanarnold/SPARCP/conda_envs/sparc_backend\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c86d3d",
   "metadata": {},
   "source": [
    "This is the backend environment verification cell. It checks that all the libraries needed for the FastAPI real-time backend are available in the active conda environment — specifically `fastapi`, `uvicorn`, `langgraph`, and the `riva.client` package for speech services.\n",
    "\n",
    "- Prints the Python executable path and version so you can confirm you're in the correct `sparc_backend` conda environment (not HiPerGator's system Python).\n",
    "- If any package is missing, it prints exactly which `conda activate` command to run to switch to the right environment, rather than crashing with an unhelpful traceback.\n",
    "- No side effects — it only reads environment state and prints diagnostics.\n",
    "\n",
    "> **Expected output if everything is correct:** `✓ All required packages available in conda environment`. If you see an error, follow the printed instructions to activate the `sparc_backend` environment before running any subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba53fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Environment Setup\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verify conda environment is activated\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Verify key packages\n",
    "try:\n",
    "    import fastapi\n",
    "    import uvicorn\n",
    "    import langgraph\n",
    "    from riva.client import ASRService\n",
    "    print(\"✓ All required packages available in conda environment\")\n",
    "except ImportError as e:\n",
    "    base_path = os.environ.get(\"SPARC_BASE_PATH\", \"/blue/jasondeanarnold/SPARCP\")\n",
    "    print(f\"ERROR: Missing package - {e}\")\n",
    "    print(\"Ensure you've activated the conda environment:\")\n",
    "    print(\"  module load conda\")\n",
    "    print(f\"  conda activate {base_path}/conda_envs/sparc_backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789a2ec",
   "metadata": {},
   "source": [
    "## 2.0 NVIDIA Riva Deployment\n",
    "Deploying the Riva server for ASR and TTS capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad88554",
   "metadata": {},
   "source": [
    "### 2.1 Riva Server Setup\n",
    "\n",
    "This section automates the setup of the NVIDIA Riva server. It downloads the `riva_quickstart` scripts from NGC. On HiPerGator, we use **Apptainer** to pull the server image (`riva-speech:2.16.0-server`). Note that `riva_init.sh` only needs to be run once to download and optimize the models.\n",
    "\n",
    "![notebook 3 - section 2-3.png](images/notebook_3_-_section_2-3.png)\n",
    "\n",
    "Riva & Guardrails Setup: This chart depicts the initialization of the speech services and safety rails. The Riva server is initialized with ASR (Speech-to-Text) and TTS (Text-to-Speech) enabled. Concurrently, NeMo Guardrails configuration files (config.yml, topical_rails.co) are generated to define the \"boundary\" of the conversation (e.g., refusing political topics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d9d5f",
   "metadata": {},
   "source": [
    "A numbered, step-by-step instruction guide for installing the NVIDIA Riva speech server on HiPerGator is printed below to follow in a HiPerGator terminal — none of the commands execute automatically.\n",
    "\n",
    "The instructions walk through four one-time setup steps:\n",
    "1. **Load Apptainer module** — enables the container runtime on HiPerGator compute nodes.\n",
    "2. **`apptainer pull`** — downloads the Riva 2.16.0 server image from NVIDIA's container registry (NGC) and saves it as a `.sif` file in your `/blue` directory. This image is ~10 GB and only needs to be downloaded once.\n",
    "3. **`riva_init.sh`** — runs inside the container to download and optimize the ASR and TTS models for your GPU architecture. This also only needs to happen once and can take 30–60 minutes.\n",
    "4. **SLURM launch** — the actual Riva server is started via the SLURM script generated in Section 7, not manually.\n",
    "\n",
    "The Riva server runs as a separate gRPC service on port `50051`. Your Python backend (the FastAPI app in Section 6) connects to it as a client using `localhost:50051` when both run on the same node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Riva Setup for HiPerGator\n",
    "import os\n",
    "\n",
    "# Define version\n",
    "RIVA_VERSION = \"2.16.0\"\n",
    "BASE_PATH = os.environ.get(\"SPARC_BASE_PATH\", \"/blue/jasondeanarnold/SPARCP\")\n",
    "RIVA_SIF_PATH = os.path.join(BASE_PATH, \"containers\", \"riva_server.sif\")\n",
    "\n",
    "def setup_riva_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for setting up Riva on HiPerGator.\n",
    "    This needs to be run once to pull and initialize the Riva container.\n",
    "    \"\"\"\n",
    "    instructions = f\"\"\"\n",
    "    === Riva Setup on HiPerGator (One-Time) ===\n",
    "    \n",
    "    1. Load required module:\n",
    "       module load apptainer\n",
    "    \n",
    "    2. Pull Riva container:\n",
    "       apptainer pull {RIVA_SIF_PATH} \\\n",
    "           docker://nvcr.io/nvidia/riva/riva-speech:{RIVA_VERSION}-server\n",
    "    \n",
    "    3. Initialize Riva models (downloads ~10GB, run on GPU node):\n",
    "       apptainer exec --nv {RIVA_SIF_PATH} riva_init.sh\n",
    "    \n",
    "    4. The Riva server will be launched via SLURM script (see Section 7)\n",
    "    \n",
    "    Note: Riva runs in its own container, while your Python backend uses\n",
    "    the conda environment (sparc_backend).\n",
    "    \"\"\"\n",
    "    print(instructions)\n",
    "    return instructions\n",
    "\n",
    "setup_riva_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c1155",
   "metadata": {},
   "source": [
    "Instructions for configuring which Riva services are enabled before running `riva_init.sh` are printed here. NVIDIA Riva can host many different AI services (speech-to-text, text-to-speech, natural language processing, etc.) — this configuration step tells it which ones to activate when the container starts.\n",
    "\n",
    "For SPARC-P, only two services are needed:\n",
    "- **ASR (Automatic Speech Recognition)** — converts the caregiver's spoken audio to text: `service_enabled_asr=true`\n",
    "- **TTS (Text-to-Speech)** — converts the AI agent's text responses back to spoken audio: `service_enabled_tts=true`\n",
    "- **NLP is disabled** (`service_enabled_nlp=false`) — SPARC-P uses its own LangGraph-based orchestration for understanding and routing, not Riva's NLP pipeline.\n",
    "\n",
    "The commented-out `sed` command at the bottom shows how you could automate this change programmatically. The current implementation just prints a reminder because the `config.sh` file only exists on the HiPerGator filesystem after the Riva quickstart scripts have been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12884b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Configure Riva (Mocking the config.sh modification)\n",
    "\n",
    "def configure_riva():\n",
    "    \"\"\"\n",
    "    Instructions to modify config.sh:\n",
    "    1. Set service_enabled_asr=true\n",
    "    2. Set service_enabled_tts=true\n",
    "    3. Set service_enabled_nlp=false (not needed for this pipeline)\n",
    "    \"\"\"\n",
    "    print(\"Please edit 'riva_quickstart_v2.16.0/config.sh' to enable ASR and TTS.\")\n",
    "    # In a real notebook, we might use sed to modify the file programmatically\n",
    "    # !sed -i 's/service_enabled_asr=false/service_enabled_asr=true/g' config.sh\n",
    "\n",
    "configure_riva()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d7608",
   "metadata": {},
   "source": [
    "### 2.3 Server Launch\n",
    "\n",
    "The following commands launch the Riva server. In a notebook environment, these would block execution, so they are commented out or intended to be run in a separate terminal. The `riva_start.sh` script spins up the containerized service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea3961",
   "metadata": {},
   "source": [
    "An execution reminder prints a message explaining that `riva_init.sh` and `riva_start.sh` must be run in a terminal (not inside this notebook). The actual `!bash` commands are commented out.\n",
    "\n",
    "Why they can't run inside the notebook:\n",
    "- `riva_init.sh` downloads models from NVIDIA's servers (up to 10 GB) and runs inside the Apptainer container — it needs the `apptainer` module loaded in a HiPerGator terminal session.\n",
    "- `riva_start.sh` starts the Riva server as a long-running background process. If run in a notebook cell, it would block the kernel indefinitely (the cell would never finish).\n",
    "\n",
    "In production deployment, the Riva server is launched as a background process by the SLURM script (`launch_backend.slurm`) generated in Section 7 — not by this notebook cell directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Launch Riva Server\n",
    "# !bash riva_init.sh\n",
    "# !bash riva_start.sh\n",
    "print(\"Run 'riva_init.sh' and 'riva_start.sh' in the terminal to launch Docker containers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06887b98",
   "metadata": {},
   "source": [
    "## 3.0 Riva Client Testing\n",
    "Verifying ASR and TTS services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba92723",
   "metadata": {},
   "source": [
    "### 3.1 Service Verification\n",
    "\n",
    "Once the server is running, we must verify connectivity. These functions use the `riva.client` library to send a gRPC request to `localhost:50051`.\n",
    "- `test_asr_service`: Streams audio chunks and prints the transcript.\n",
    "- `test_tts_service`: Sends text and saves the synthesized audio to a WAV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5012dbe",
   "metadata": {},
   "source": [
    "Two test functions verify that the Riva speech server is reachable and responding correctly, connecting to it via gRPC.\n",
    "\n",
    "What happens when you run this:\n",
    "- **`riva.client.Auth(uri='localhost:50051')`**: Creates an authenticated gRPC channel to the Riva server at `localhost:50051` (the default Riva port). This line actually attempts a connection — if Riva isn't running, this will raise a connection error.\n",
    "- **`test_asr_service(audio_file_path)`**: Would stream a WAV audio file to Riva's ASR service and print back the transcription. Currently simulated with a print statement — uncomment the internal Riva calls once the server is live.\n",
    "- **`test_tts_service(text_input)`**: Would send a text string to Riva's TTS service and receive synthesized audio, saved to `output.wav`. Also simulated here.\n",
    "\n",
    "The two uncommented example calls at the bottom (`# test_asr_service('sample.wav')` and `# test_tts_service(...)`) show exactly how to run these tests. Uncomment them after starting the Riva server to confirm that speech services are working before running the full backend.\n",
    "\n",
    "> **Prerequisite:** The Riva server must be running (`riva_start.sh` completed) for these tests to actually connect. Running them with the server offline will produce a gRPC connection error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc536cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import riva.client\n",
    "\n",
    "auth = riva.client.Auth(uri='localhost:50051')\n",
    "\n",
    "def test_asr_service(audio_file_path):\n",
    "    print(f\"Testing ASR with {audio_file_path}...\")\n",
    "    # asr_service = riva.client.ASRService(auth)\n",
    "    # Logic to stream audio and get transcript\n",
    "    print(\"ASR Test Passed: [Simulated Transcript]\")\n",
    "\n",
    "def test_tts_service(text_input):\n",
    "    print(f\"Testing TTS with '{text_input}'...\")\n",
    "    # tts_service = riva.client.TTSService(auth)\n",
    "    # Logic to generate audio\n",
    "    print(\"TTS Test Passed: Output saved to output.wav\")\n",
    "\n",
    "# Uncomment to run if server is live\n",
    "# test_asr_service('sample.wav')\n",
    "# test_tts_service('Hello from SPARC-P')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb942c",
   "metadata": {},
   "source": [
    "### 3.2 NeMo Guardrails Configuration\n",
    "\n",
    "Safety is critical. The configuration files for **NVIDIA NeMo Guardrails** are generated programmatically here:\n",
    "- `config.yml`: Defines the LLM connection.\n",
    "- `topical_rails.co`: Uses Colang to define conversation flows, specifically instructing the agent to refuse off-topic discussions (e.g., politics) and stay focused on HPV vaccination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa47cc5a",
   "metadata": {},
   "source": [
    "Two configuration files are generated here that define the AI safety boundaries for SPARC-P — the \"guardrails\" that prevent the AI agents from discussing anything outside of HPV vaccination and clinical communication training.\n",
    "\n",
    "The two files created:\n",
    "- **`config.yml`**: Tells NeMo Guardrails which AI model is powering the system (the fine-tuned SPARC-P adapter stored in the `/blue` trained models directory). NeMo Guardrails loads this model when evaluating whether a message violates the conversation rules.\n",
    "- **`topical_rails.co`**: Written in Colang (NVIDIA's domain-specific language for conversation flows), this file defines conversation patterns:\n",
    "  - **\"User asks about anything else\"** — examples like politics, finance, sports that are off-topic for a vaccine communication training tool\n",
    "  - **\"Bot refuses to answer\"** — the polite refusal messages the AI will use when the conversation veers off-topic\n",
    "  - **Flow rule**: Connects the trigger (off-topic question) to the response (refusal), so any message matching the trigger pattern gets the refusal response automatically\n",
    "\n",
    "Both files are saved to the directory specified by `SPARC_GUARDRAILS_DIR` (defaulting to `<BASE_PATH>/guardrails/`). The `SupervisorAgent` class in Section 5 loads these files at startup using `RailsConfig.from_path()`.\n",
    "\n",
    "> **Why this matters:** Without guardrails, a caregiver could ask the AI to help them with completely unrelated tasks. The guardrails keep the system on-topic and appropriate for the educational context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 NeMo Guardrails Configuration\n",
    "import os\n",
    "\n",
    "def create_rails_config():\n",
    "    base_path = os.environ.get(\"SPARC_BASE_PATH\", \"/blue/jasondeanarnold/SPARCP\")\n",
    "    guardrails_dir = os.environ.get(\"SPARC_GUARDRAILS_DIR\", os.path.join(base_path, \"guardrails\"))\n",
    "    os.makedirs(guardrails_dir, exist_ok=True)\n",
    "\n",
    "    # 1. config.yml\n",
    "    model_path = os.path.join(base_path, \"trained_models\", \"sparc-agent-final\")\n",
    "\n",
    "    config_content = f\"\"\"\n",
    "models:\n",
    "  - type: main\n",
    "    engine: huggingface\n",
    "    model: {model_path}\n",
    "    \"\"\"\n",
    "    with open(os.path.join(guardrails_dir, \"config.yml\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(config_content.strip())\n",
    "\n",
    "    # 2. topical_rails.co\n",
    "    rails_content = \"\"\"\n",
    "define user ask about anything else\n",
    "  \"tell me about politics\"\n",
    "  \"what are your thoughts on finance?\"\n",
    "  \"who will win the game?\"\n",
    "\n",
    "define bot refuse to answer\n",
    "  \"I'm sorry, but I can only discuss topics related to HPV vaccination.\"\n",
    "  \"My purpose is to help you practice clinical communication skills for HPV vaccines.\"\n",
    "\n",
    "define flow\n",
    "  user ask about anything else\n",
    "  bot refuse to answer\n",
    "    \"\"\"\n",
    "    with open(os.path.join(guardrails_dir, \"topical_rails.co\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(rails_content.strip())\n",
    "\n",
    "    print(f\"NeMo Guardrails configuration files created in {guardrails_dir}\")\n",
    "    return guardrails_dir\n",
    "\n",
    "create_rails_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8cac7",
   "metadata": {},
   "source": [
    "## 4.0 Coach Voice Cloning (Zero-Shot TTS)\n",
    "\n",
    "Riva 2.x supports **zero-shot voice cloning natively** — no NeMo fine-tuning pipeline required. By providing a short (3–10 second) audio prompt, Riva's TTS engine adapts its output to match the speaker's vocal characteristics at inference time.\n",
    "\n",
    "This section clones the Coach AI voice from sample recordings in `audio/coach_examples/`:\n",
    "1. **4.1 Audio Preprocessing** — Scans the directory, converts all clips to Riva's required format (16 kHz mono PCM WAV), and selects the single best 3–10 second prompt.\n",
    "2. **4.2 Test Synthesis** — Validates the prompt against a live Riva endpoint and writes a reference output for listening quality checks.\n",
    "3. **4.3 `CoachVoiceConfig`** — A dataclass that bundles the prompt path, its transcript, and quality settings. `CoachAgent` accepts this config and uses the cloned voice when synthesizing feedback audio; it falls back to the default TTS voice gracefully if Riva is offline or no config is provided.\n",
    "\n",
    "![notebook 3 - section 4.png](images/notebook_3_-_section_4.png)\n",
    "\n",
    "Coach Voice Cloning: The diagram shows the zero-shot cloning pipeline. Audio files from `audio/coach_examples/` are preprocessed into a 16 kHz mono WAV prompt. That prompt is passed to the Riva TTS `synthesize()` call alongside the Coach's feedback text. Riva adapts its output to match the prompt speaker's voice without any separate training job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e09835",
   "metadata": {},
   "source": [
    "### 4.1 Audio Preprocessing\n",
    "\n",
    "Scans `audio/coach_examples/` for `.mp3` and `.wav` files, converts each to **16 kHz mono PCM WAV** (Riva's required input format), and selects the single best clip to use as the cloning prompt.\n",
    "\n",
    "Selection criteria (applied in this order):\n",
    "1. **Duration gate**: Only clips between 3 and 10 seconds are eligible — Riva rejects prompts outside this range.\n",
    "2. **Target duration**: Prefers clips closest to 7 seconds (empirically the best balance between enough voice data and voice drift).\n",
    "3. **RMS energy**: Among clips equally close to 7 seconds, selects the louder one (better signal-to-noise ratio).\n",
    "\n",
    "The chosen prompt WAV is written to `audio/coach_examples/processed/best_prompt.wav`. A summary table is printed showing all discovered clips and why the winner was selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ab5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Audio Preprocessing — Select and convert best prompt clip\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    PYDUB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYDUB_AVAILABLE = False\n",
    "    print(\"WARNING: pydub not installed. Run: pip install pydub\")\n",
    "    print(\"         ffmpeg must also be on PATH for mp3 support.\")\n",
    "\n",
    "BASE_PATH = os.environ.get(\"SPARC_BASE_PATH\", \"/blue/jasondeanarnold/SPARCP\")\n",
    "EXAMPLES_DIR = Path(BASE_PATH) / \"audio\" / \"coach_examples\"\n",
    "PROCESSED_DIR = EXAMPLES_DIR / \"processed\"\n",
    "BEST_PROMPT_PATH = PROCESSED_DIR / \"best_prompt.wav\"\n",
    "TARGET_DURATION_S = 7.0   # seconds — empirically optimal for zero-shot cloning\n",
    "MIN_DURATION_S = 3.0\n",
    "MAX_DURATION_S = 10.0\n",
    "TARGET_SAMPLE_RATE = 16000\n",
    "\n",
    "def preprocess_prompt_clips(examples_dir: Path, processed_dir: Path) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Converts all .mp3 and .wav files in examples_dir to 16 kHz mono PCM WAV,\n",
    "    measures duration and RMS energy, and returns a list of candidate dicts.\n",
    "    \"\"\"\n",
    "    processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "    candidates = []\n",
    "\n",
    "    audio_files = sorted(\n",
    "        [f for f in examples_dir.iterdir() if f.suffix.lower() in (\".mp3\", \".wav\") and f.is_file()]\n",
    "    )\n",
    "    if not audio_files:\n",
    "        print(f\"No .mp3 or .wav files found in {examples_dir}\")\n",
    "        return candidates\n",
    "\n",
    "    for src in audio_files:\n",
    "        try:\n",
    "            seg = AudioSegment.from_file(str(src))\n",
    "            seg = seg.set_frame_rate(TARGET_SAMPLE_RATE).set_channels(1).set_sample_width(2)\n",
    "            duration_s = len(seg) / 1000.0\n",
    "            rms = seg.rms\n",
    "\n",
    "            dest = processed_dir / (src.stem + \"_16k.wav\")\n",
    "            seg.export(str(dest), format=\"wav\")\n",
    "\n",
    "            candidates.append({\n",
    "                \"src\": src.name,\n",
    "                \"dest\": dest,\n",
    "                \"duration_s\": round(duration_s, 2),\n",
    "                \"rms\": rms,\n",
    "                \"eligible\": MIN_DURATION_S <= duration_s <= MAX_DURATION_S,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"  SKIP {src.name}: {e}\")\n",
    "\n",
    "    return candidates\n",
    "\n",
    "def select_best_prompt(candidates: list[dict]) -> dict | None:\n",
    "    \"\"\"Picks the clip closest to TARGET_DURATION_S, breaking ties by RMS.\"\"\"\n",
    "    eligible = [c for c in candidates if c[\"eligible\"]]\n",
    "    if not eligible:\n",
    "        return None\n",
    "    return min(eligible, key=lambda c: (abs(c[\"duration_s\"] - TARGET_DURATION_S), -c[\"rms\"]))\n",
    "\n",
    "if PYDUB_AVAILABLE:\n",
    "    if not EXAMPLES_DIR.exists():\n",
    "        print(f\"Creating example directory: {EXAMPLES_DIR}\")\n",
    "        EXAMPLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"Place .mp3 or .wav coach recordings in that directory, then re-run this cell.\")\n",
    "    else:\n",
    "        candidates = preprocess_prompt_clips(EXAMPLES_DIR, PROCESSED_DIR)\n",
    "        best = select_best_prompt(candidates)\n",
    "\n",
    "        # Print summary table\n",
    "        print(f\"{'File':<35} {'Duration':>9} {'RMS':>7} {'Eligible':>9} {'Selected':>9}\")\n",
    "        print(\"-\" * 73)\n",
    "        for c in candidates:\n",
    "            sel = \"<-- SELECTED\" if best and c[\"dest\"] == best[\"dest\"] else \"\"\n",
    "            elig = \"yes\" if c[\"eligible\"] else f\"no ({c['duration_s']:.1f}s)\"\n",
    "            print(f\"{c['src']:<35} {c['duration_s']:>8.2f}s {c['rms']:>7} {elig:>9} {sel}\")\n",
    "\n",
    "        if best:\n",
    "            import shutil\n",
    "            shutil.copy2(str(best[\"dest\"]), str(BEST_PROMPT_PATH))\n",
    "            print(f\"\\nBest prompt copied to: {BEST_PROMPT_PATH}\")\n",
    "            print(f\"  Duration : {best['duration_s']}s\")\n",
    "            print(f\"  RMS      : {best['rms']}\")\n",
    "            COACH_PROMPT_TRANSCRIPT = input(\n",
    "                \"\\nEnter the transcript of the selected audio clip (exact words spoken): \"\n",
    "            ).strip()\n",
    "            print(f\"Transcript set: '{COACH_PROMPT_TRANSCRIPT}'\")\n",
    "        else:\n",
    "            print(\"\\nNo eligible clips found (need 3–10 second recordings). \"\n",
    "                  \"Add files to audio/coach_examples/ and re-run.\")\n",
    "            COACH_PROMPT_TRANSCRIPT = \"\"\n",
    "else:\n",
    "    COACH_PROMPT_TRANSCRIPT = \"\"\n",
    "    BEST_PROMPT_PATH = Path(\"/tmp/best_prompt_placeholder.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b60fe5c",
   "metadata": {},
   "source": [
    "### 4.2 Voice Prompt Validation and Test Synthesis\n",
    "\n",
    "Validates the selected prompt by calling Riva's `synthesize()` API with the zero-shot parameters and writing the output to `audio/coach_voice_test.wav`. Listen to this file to verify voice quality before deploying.\n",
    "\n",
    "Key parameters:\n",
    "- **`zero_shot_audio_prompt_file`**: Path to the 16 kHz mono WAV prompt from Section 4.1.\n",
    "- **`zero_shot_transcript`**: The exact words spoken in the prompt clip — Riva uses this to align phonemes; accuracy directly affects voice similarity.\n",
    "- **`zero_shot_quality`**: Integer 1–40. Higher = slower inference but better voice match. Default of `20` balances latency and quality for real-time coaching.\n",
    "- **`sample_rate_hz`**: Output sample rate set to 44100 Hz for audio playback compatibility.\n",
    "\n",
    "If Riva is offline (e.g., running this cell outside of HiPerGator), the cell prints a dry-run summary instead of failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00481869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Voice Prompt Validation and Test Synthesis\n",
    "import wave\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "RIVA_SERVER = os.environ.get(\"SPARC_RIVA_SERVER\", \"localhost:50051\")\n",
    "TEST_OUTPUT_PATH = Path(BASE_PATH) / \"audio\" / \"coach_voice_test.wav\"\n",
    "TEST_TEXT = (\n",
    "    \"Great job maintaining eye contact and using affirming language. \"\n",
    "    \"Next time, try pausing after your empathy statement to give the caregiver more space to respond.\"\n",
    ")\n",
    "ZERO_SHOT_QUALITY = 20   # 1–40; 20 is the mid-range default\n",
    "\n",
    "def _prompt_is_valid(prompt_path: Path) -> bool:\n",
    "    \"\"\"Returns True if the file exists, is > 0 bytes, and is valid PCM WAV.\"\"\"\n",
    "    if not prompt_path.exists() or prompt_path.stat().st_size == 0:\n",
    "        return False\n",
    "    try:\n",
    "        with wave.open(str(prompt_path), \"rb\") as wf:\n",
    "            return wf.getnchannels() == 1 and wf.getframerate() == 16000\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def run_test_synthesis(prompt_path: Path, transcript: str, output_path: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Calls Riva zero-shot TTS and writes the result to output_path.\n",
    "    Returns True on success, False on any connection or API error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import riva.client\n",
    "        channel = riva.client.connect(RIVA_SERVER)\n",
    "        tts_service = riva.client.SpeechSynthesisService(channel)\n",
    "\n",
    "        resp = tts_service.synthesize(\n",
    "            TEST_TEXT,\n",
    "            \"English-US.Female-1\",     # base voice — zero-shot overrides timbre\n",
    "            \"en-US\",\n",
    "            sample_rate_hz=44100,\n",
    "            zero_shot_audio_prompt_file=prompt_path,\n",
    "            zero_shot_quality=ZERO_SHOT_QUALITY,\n",
    "            zero_shot_transcript=transcript,\n",
    "        )\n",
    "\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(str(output_path), \"wb\") as f:\n",
    "            f.write(resp.audio)\n",
    "        print(f\"Test synthesis written to: {output_path}\")\n",
    "        print(f\"  Audio bytes : {len(resp.audio):,}\")\n",
    "        return True\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"riva.client not installed — install the Riva Python client package.\")\n",
    "        return False\n",
    "    except Exception as err:\n",
    "        print(f\"Riva TTS unavailable ({err}) — dry-run mode.\")\n",
    "        print(f\"  Would synthesize : '{TEST_TEXT[:60]}...'\")\n",
    "        print(f\"  Prompt file      : {prompt_path}\")\n",
    "        print(f\"  Quality setting  : {ZERO_SHOT_QUALITY}\")\n",
    "        print(f\"  Output target    : {output_path}\")\n",
    "        return False\n",
    "\n",
    "if _prompt_is_valid(BEST_PROMPT_PATH):\n",
    "    print(f\"Prompt validated: {BEST_PROMPT_PATH} ({BEST_PROMPT_PATH.stat().st_size:,} bytes)\")\n",
    "    success = run_test_synthesis(BEST_PROMPT_PATH, COACH_PROMPT_TRANSCRIPT, TEST_OUTPUT_PATH)\n",
    "    if success:\n",
    "        print(\"\\nListen to coach_voice_test.wav to verify voice quality before deployment.\")\n",
    "else:\n",
    "    print(f\"Prompt not yet available at {BEST_PROMPT_PATH}.\")\n",
    "    print(\"Run Section 4.1 first to preprocess audio clips.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97540df5",
   "metadata": {},
   "source": [
    "### 4.3 `CoachVoiceConfig` — Zero-Shot Voice Profile\n",
    "\n",
    "`CoachVoiceConfig` is a lightweight dataclass that bundles everything `CoachAgent` needs to use the cloned voice:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `prompt_path` | `Path` | Path to the 16 kHz mono WAV prompt from Section 4.1 |\n",
    "| `transcript` | `str` | Exact words spoken in the prompt — must match precisely |\n",
    "| `quality` | `int` | Zero-shot quality 1–40 (default 20) |\n",
    "| `language_code` | `str` | BCP-47 language tag (default `\"en-US\"`) |\n",
    "| `voice_name` | `str` | Base Riva voice the adaptation starts from |\n",
    "\n",
    "`CoachAgent` is updated to accept an optional `CoachVoiceConfig`. When the config is provided and Riva is reachable, `evaluate_turn()` returns both text feedback and base64-encoded audio synthesized in the cloned voice. When Riva is offline or no config is given, it falls back to returning text-only feedback — the orchestrator continues to run normally.\n",
    "\n",
    "`build_app_graph()` is updated to attempt loading the config from `audio/coach_examples/processed/best_prompt.wav` at startup. If the file does not exist (e.g., first deployment before Section 4.1 has been run), it starts with voice cloning disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ace52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 CoachVoiceConfig dataclass\n",
    "import base64\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class CoachVoiceConfig:\n",
    "    \"\"\"\n",
    "    Zero-shot voice cloning configuration for CoachAgent.\n",
    "\n",
    "    Attributes:\n",
    "        prompt_path:   Path to a 16 kHz mono PCM WAV file (3–10 seconds).\n",
    "        transcript:    Exact words spoken in the prompt clip.\n",
    "        quality:       Zero-shot quality 1–40. Higher = better voice match, slower inference.\n",
    "        language_code: BCP-47 language tag for TTS synthesis.\n",
    "        voice_name:    Base Riva voice the zero-shot adaptation starts from.\n",
    "        riva_server:   Host:port of the running Riva gRPC endpoint.\n",
    "    \"\"\"\n",
    "    prompt_path: Path\n",
    "    transcript: str\n",
    "    quality: int = 20\n",
    "    language_code: str = \"en-US\"\n",
    "    voice_name: str = \"English-US.Female-1\"\n",
    "    riva_server: str = field(\n",
    "        default_factory=lambda: os.environ.get(\"SPARC_RIVA_SERVER\", \"localhost:50051\")\n",
    "    )\n",
    "\n",
    "    def is_ready(self) -> bool:\n",
    "        \"\"\"True if the prompt file exists and has content.\"\"\"\n",
    "        return self.prompt_path.exists() and self.prompt_path.stat().st_size > 0\n",
    "\n",
    "\n",
    "def load_coach_voice_config(\n",
    "    processed_dir: Optional[Path] = None,\n",
    "    transcript: str = \"\",\n",
    "    quality: int = 20,\n",
    ") -> Optional[CoachVoiceConfig]:\n",
    "    \"\"\"\n",
    "    Factory function called at startup.  Returns a CoachVoiceConfig if\n",
    "    best_prompt.wav exists in processed_dir, otherwise returns None so the\n",
    "    system starts with voice cloning disabled (text-only fallback).\n",
    "    \"\"\"\n",
    "    base = os.environ.get(\"SPARC_BASE_PATH\", \"/blue/jasondeanarnold/SPARCP\")\n",
    "    prompt = (processed_dir or Path(base) / \"audio\" / \"coach_examples\" / \"processed\") / \"best_prompt.wav\"\n",
    "\n",
    "    if not prompt.exists():\n",
    "        print(f\"CoachVoiceConfig: prompt not found at {prompt} — voice cloning disabled.\")\n",
    "        return None\n",
    "\n",
    "    cfg = CoachVoiceConfig(prompt_path=prompt, transcript=transcript, quality=quality)\n",
    "    print(f\"CoachVoiceConfig loaded: {prompt} (quality={quality})\")\n",
    "    return cfg\n",
    "\n",
    "\n",
    "# Preview (won't error even if prompt doesn't exist yet)\n",
    "_preview_cfg = load_coach_voice_config(transcript=COACH_PROMPT_TRANSCRIPT)\n",
    "if _preview_cfg:\n",
    "    print(f\"  Voice cloning ENABLED — prompt: {_preview_cfg.prompt_path.name}\")\n",
    "    print(f\"  Transcript   : '{_preview_cfg.transcript}'\")\n",
    "    print(f\"  Quality      : {_preview_cfg.quality}\")\n",
    "else:\n",
    "    print(\"  Voice cloning DISABLED — run Section 4.1 to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a0d11",
   "metadata": {},
   "source": [
    "## 5.0 Multi-Agent Orchestration (LangGraph)\n",
    "Implements the Supervisor-Worker architecture using a state graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db6a39",
   "metadata": {},
   "source": [
    "### 5.1 Multi-Agent Orchestration Logic\n",
    "\n",
    "This section implements the core reasoning loop using `asyncio` for concurrency. We define three agent classes:\n",
    "- **Supervisor**: Checks input safety using NeMo Guardrails.\n",
    "- **Caregiver**: Generates the persona response (simulating RAG+LLM latency).\n",
    "- **Coach**: Evaluates the turn (simulating C-LEAR rubric latency).\n",
    "\n",
    "The `handle_user_turn` function orchestrates these agents, running the Caregiver and Coach in parallel to minimize response time.\n",
    "\n",
    "\n",
    "![notebook 3 - section 5.png](images/notebook_3_-_section_5.png)\n",
    "\n",
    "Multi-Agent Orchestration (LangGraph): This is the core logic of the backend. It visualizes the Supervisor-Worker pattern. The User Input is first checked by the Supervisor (Guardrails). If safe, it triggers the Caregiver (generating the response) and the Coach (evaluating the response) in parallel to minimize latency. The results are aggregated into a single JSON response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11919a97",
   "metadata": {},
   "source": [
    "The core multi-agent backend — a 156-line implementation of the real-time conversation orchestration system. When a caregiver speaks to SPARC-P, the orchestrator decides what happens to their words and who responds.\n",
    "\n",
    "The four classes defined here, and what each does:\n",
    "\n",
    "**`SupervisorAgent`**: The safety gatekeeper. Every user message goes through this agent first. It loads the NeMo Guardrails configuration and checks whether the input is on-topic. If it's off-topic or harmful, it returns a pre-set refusal message and sets `is_safe=False`. It also checks the Caregiver's *response* (not just the input) before sending it to the user. The two-stage checking (input + output) prevents both prompt injection and model hallucinations from leaking inappropriate content.\n",
    "\n",
    "**`CaregiverAgent`**: Simulates 800ms of LLM inference latency (in production, this calls the fine-tuned caregiver model). Returns the avatar's spoken response text.\n",
    "\n",
    "**`CoachAgent`**: Simulates 400ms of LLM inference latency (in production, this calls the fine-tuned C-LEAR coach model). Returns structured feedback on the trainee's communication.\n",
    "\n",
    "**`handle_user_turn()`**: The orchestration function that sequences the above agents:\n",
    "1. Supervisor checks input (if unsafe → return refusal immediately)\n",
    "2. Caregiver and Coach run **simultaneously** using `asyncio.gather()` — this parallel execution is critical for keeping response time under 1.5 seconds even though two LLMs are involved\n",
    "3. Supervisor checks the combined output (second safety pass)\n",
    "\n",
    "**`AsyncOrchestrationGraph`**: A thin adapter class that wraps `handle_user_turn()` with an `ainvoke(state)` interface. This makes it compatible with the FastAPI endpoint in Section 6 without requiring LangGraph compilation.\n",
    "\n",
    "**`build_app_graph()`**: The factory function called at startup by the FastAPI application to create the orchestrator instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ce485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import os\n",
    "from typing import Any, Dict, Optional\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# 3.3 Multi-Agent System (MAS) Orchestration Logic\n",
    "\n",
    "class SupervisorAgent:\n",
    "    def __init__(self, rails_path: str = None):\n",
    "        self.refusal_message = \"I can only discuss topics related to HPV vaccination and clinical communication training.\"\n",
    "        base_path = os.environ.get(\"SPARC_BASE_PATH\", \"/blue/jasondeanarnold/SPARCP\")\n",
    "        self.rails_path = rails_path or os.environ.get(\"SPARC_GUARDRAILS_DIR\", os.path.join(base_path, \"guardrails\"))\n",
    "        self.rails = None\n",
    "        try:\n",
    "            rails_config = RailsConfig.from_path(self.rails_path)\n",
    "            self.rails = LLMRails(rails_config)\n",
    "            self.guardrails_ready = True\n",
    "        except Exception as rails_error:\n",
    "            print(f\"SUPERVISOR: Failed to load guardrails from {self.rails_path}: {rails_error}\")\n",
    "            self.guardrails_ready = False\n",
    "\n",
    "    async def _run_rails(self, user_text: str) -> str:\n",
    "        if not self.rails:\n",
    "            raise RuntimeError(\"Guardrails runtime is not initialized\")\n",
    "        messages = [{\"role\": \"user\", \"content\": user_text}]\n",
    "        if hasattr(self.rails, \"generate_async\"):\n",
    "            result = await self.rails.generate_async(messages=messages)\n",
    "        else:\n",
    "            result = self.rails.generate(messages=messages)\n",
    "\n",
    "        if isinstance(result, dict):\n",
    "            if \"content\" in result:\n",
    "                return str(result[\"content\"])\n",
    "            return str(result)\n",
    "        return str(result)\n",
    "\n",
    "    async def process_input(self, text: str):\n",
    "        print(f\"SUPERVISOR: Checking input '{text}'\")\n",
    "        if not text or not text.strip():\n",
    "            return self.refusal_message, False, \"empty_input\"\n",
    "        if not self.guardrails_ready:\n",
    "            return self.refusal_message, False, \"guardrails_unavailable\"\n",
    "\n",
    "        try:\n",
    "            rails_output = await self._run_rails(text)\n",
    "            refusal_detected = self.refusal_message.lower() in rails_output.lower()\n",
    "            if refusal_detected:\n",
    "                return self.refusal_message, False, \"input_rails_blocked\"\n",
    "            return text, True, \"input_rails_allowed\"\n",
    "        except Exception as rails_error:\n",
    "            print(f\"SUPERVISOR: Guardrails input evaluation failed: {rails_error}\")\n",
    "            return self.refusal_message, False, \"input_rails_error\"\n",
    "\n",
    "    async def enforce_output(self, text: str):\n",
    "        if not text or not text.strip():\n",
    "            return self.refusal_message, False, \"empty_output\"\n",
    "        if not self.guardrails_ready:\n",
    "            return self.refusal_message, False, \"guardrails_unavailable\"\n",
    "\n",
    "        try:\n",
    "            rails_output = await self._run_rails(text)\n",
    "            refusal_detected = self.refusal_message.lower() in rails_output.lower()\n",
    "            if refusal_detected:\n",
    "                return self.refusal_message, False, \"output_rails_blocked\"\n",
    "            return text, True, \"output_rails_allowed\"\n",
    "        except Exception as rails_error:\n",
    "            print(f\"SUPERVISOR: Guardrails output evaluation failed: {rails_error}\")\n",
    "            return self.refusal_message, False, \"output_rails_error\"\n",
    "\n",
    "\n",
    "class CaregiverAgent:\n",
    "    async def generate_response(self, text: str):\n",
    "        await asyncio.sleep(0.8)\n",
    "        return f\"Caregiver response to: {text}\"\n",
    "\n",
    "\n",
    "class CoachAgent:\n",
    "    \"\"\"\n",
    "    Evaluates the trainee's conversational turn and optionally synthesizes\n",
    "    feedback audio using zero-shot voice cloning via Riva TTS.\n",
    "\n",
    "    When a CoachVoiceConfig is provided and Riva is reachable, evaluate_turn()\n",
    "    returns (feedback_text, base64_audio_wav).  When voice cloning is not\n",
    "    configured or Riva is unavailable, it returns (feedback_text, \"\"),\n",
    "    and the orchestrator continues normally with text-only feedback.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, voice_config: Optional[\"CoachVoiceConfig\"] = None):\n",
    "        self.voice_config = voice_config\n",
    "        self._riva_channel = None\n",
    "        self._tts_service = None\n",
    "\n",
    "        if voice_config and voice_config.is_ready():\n",
    "            try:\n",
    "                import riva.client\n",
    "                self._riva_channel = riva.client.connect(voice_config.riva_server)\n",
    "                self._tts_service = riva.client.SpeechSynthesisService(self._riva_channel)\n",
    "                print(f\"COACH: Zero-shot TTS ready — prompt: {voice_config.prompt_path.name}\")\n",
    "            except Exception as err:\n",
    "                print(f\"COACH: Riva TTS unavailable ({err}) — text-only fallback active.\")\n",
    "                self._tts_service = None\n",
    "\n",
    "    async def _synthesize_feedback(self, feedback_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls Riva zero-shot TTS synchronously (in a thread executor to avoid\n",
    "        blocking the async event loop) and returns base64-encoded WAV audio.\n",
    "        Returns empty string on any error.\n",
    "        \"\"\"\n",
    "        if not self._tts_service or not self.voice_config:\n",
    "            return \"\"\n",
    "\n",
    "        def _call_riva():\n",
    "            return self._tts_service.synthesize(\n",
    "                feedback_text,\n",
    "                self.voice_config.voice_name,\n",
    "                self.voice_config.language_code,\n",
    "                sample_rate_hz=44100,\n",
    "                zero_shot_audio_prompt_file=self.voice_config.prompt_path,\n",
    "                zero_shot_quality=self.voice_config.quality,\n",
    "                zero_shot_transcript=self.voice_config.transcript,\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            resp = await loop.run_in_executor(None, _call_riva)\n",
    "            return base64.b64encode(resp.audio).decode(\"utf-8\")\n",
    "        except Exception as tts_err:\n",
    "            print(f\"COACH TTS synthesis failed: {tts_err}\")\n",
    "            return \"\"\n",
    "\n",
    "    async def evaluate_turn(self, text: str):\n",
    "        await asyncio.sleep(0.4)\n",
    "        feedback_text = \"Good empathy.\"\n",
    "        audio_b64 = await self._synthesize_feedback(feedback_text)\n",
    "        return feedback_text, audio_b64\n",
    "\n",
    "\n",
    "async def handle_user_turn(user_transcript: str, supervisor, caregiver, coach):\n",
    "    sanitized_text, is_safe, safety_reason = await supervisor.process_input(user_transcript)\n",
    "    if not is_safe:\n",
    "        return {\n",
    "            \"final_text\": sanitized_text,\n",
    "            \"coach_feedback\": \"\",\n",
    "            \"coach_audio\": \"\",\n",
    "            \"safety\": {\"is_safe\": False, \"reason\": safety_reason},\n",
    "        }\n",
    "\n",
    "    caregiver_task = asyncio.create_task(caregiver.generate_response(sanitized_text))\n",
    "    coach_task = asyncio.create_task(coach.evaluate_turn(sanitized_text))\n",
    "    caregiver_response, (coach_feedback, coach_audio) = await asyncio.gather(caregiver_task, coach_task)\n",
    "\n",
    "    final_response = f\"{caregiver_response} [Feedback: {coach_feedback}]\"\n",
    "    output_text, output_safe, output_reason = await supervisor.enforce_output(final_response)\n",
    "    return {\n",
    "        \"final_text\": output_text,\n",
    "        \"coach_feedback\": coach_feedback if output_safe else \"\",\n",
    "        \"coach_audio\": coach_audio if output_safe else \"\",\n",
    "        \"safety\": {\"is_safe\": output_safe, \"reason\": output_reason},\n",
    "    }\n",
    "\n",
    "\n",
    "class AsyncOrchestrationGraph:\n",
    "    \"\"\"\n",
    "    Minimal async graph adapter to provide an app_graph.ainvoke(...) interface.\n",
    "    This preserves a clear initialization lifecycle without requiring notebook-wide\n",
    "    LangGraph compilation for the prototype.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, supervisor: SupervisorAgent, caregiver: CaregiverAgent, coach: CoachAgent):\n",
    "        self.supervisor = supervisor\n",
    "        self.caregiver = caregiver\n",
    "        self.coach = coach\n",
    "\n",
    "    async def ainvoke(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        transcript = state.get(\"transcript\", \"\")\n",
    "        if not isinstance(transcript, str) or not transcript.strip():\n",
    "            return {\n",
    "                \"final_response\": {\"text\": \"No transcript provided.\", \"audio\": \"\", \"cues\": {}},\n",
    "                \"feedback\": \"\",\n",
    "                \"coach_audio\": \"\",\n",
    "                \"safety\": {\"is_safe\": False, \"reason\": \"empty_transcript\"},\n",
    "            }\n",
    "\n",
    "        turn_result = await handle_user_turn(\n",
    "            transcript,\n",
    "            self.supervisor,\n",
    "            self.caregiver,\n",
    "            self.coach,\n",
    "        )\n",
    "\n",
    "        caregiver_text = turn_result.get(\"final_text\", \"Error\")\n",
    "        coach_feedback = turn_result.get(\"coach_feedback\", \"\")\n",
    "        coach_audio = turn_result.get(\"coach_audio\", \"\")\n",
    "        safety = turn_result.get(\"safety\", {\"is_safe\": False, \"reason\": \"unknown\"})\n",
    "\n",
    "        if \" [Feedback: \" in caregiver_text and caregiver_text.endswith(\"]\"):\n",
    "            caregiver_text, feedback_tail = caregiver_text.rsplit(\" [Feedback: \", 1)\n",
    "            coach_feedback = feedback_tail[:-1]\n",
    "\n",
    "        return {\n",
    "            \"final_response\": {\n",
    "                \"text\": caregiver_text,\n",
    "                \"audio\": \"\",\n",
    "                \"cues\": {\"gesture\": \"speaking\"},\n",
    "            },\n",
    "            \"feedback\": coach_feedback,\n",
    "            \"coach_audio\": coach_audio,\n",
    "            \"safety\": safety,\n",
    "        }\n",
    "\n",
    "\n",
    "def build_app_graph() -> AsyncOrchestrationGraph:\n",
    "    \"\"\"\n",
    "    Canonical orchestrator construction lifecycle for the backend endpoint.\n",
    "    Attempts to load CoachVoiceConfig from audio/coach_examples/processed/best_prompt.wav.\n",
    "    If the prompt does not exist, CoachAgent starts with voice cloning disabled (text-only).\n",
    "    \"\"\"\n",
    "    supervisor = SupervisorAgent()\n",
    "    caregiver = CaregiverAgent()\n",
    "\n",
    "    # Load zero-shot voice config — safe to call even before Section 4.1 has been run.\n",
    "    # COACH_PROMPT_TRANSCRIPT is set in Section 4.1; falls back to \"\" gracefully.\n",
    "    _prompt_transcript = globals().get(\"COACH_PROMPT_TRANSCRIPT\", \"\")\n",
    "    voice_cfg = load_coach_voice_config(transcript=_prompt_transcript)\n",
    "    coach = CoachAgent(voice_config=voice_cfg)\n",
    "\n",
    "    return AsyncOrchestrationGraph(supervisor, caregiver, coach)\n",
    "\n",
    "# Example Run\n",
    "# app_graph = build_app_graph()\n",
    "# asyncio.run(app_graph.ainvoke({\"transcript\": \"User said something about vaccines\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897c430",
   "metadata": {},
   "source": [
    "## 6.0 API Server (FastAPI)\n",
    "Exposes the Orchestrator to the Unity Client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471867cb",
   "metadata": {},
   "source": [
    "### 6.1 FastAPI Server Implementation\n",
    "\n",
    "The orchestration logic is wrapped in a **FastAPI** application to expose it to the Unity client.\n",
    "- **`/v1/chat` Endpoint**: Accepts a user transcript and session ID, invokes the orchestration loop, and returns the multi-agent response (Text, Audio, Feedback).\n",
    "- **Redacted Audit Logging**: Writes only compliant metadata (`session_id`, `agent_type`, `is_safe`, `latency_ms`, timestamp) and excludes raw transcript content.\n",
    "- **Health Check**: A simple `GET /health` endpoint for monitoring service uptime and audit retention metadata.\n",
    "\n",
    "![notebook 3 - section 6.png](images/notebook_3_-_section_6.png)\n",
    "\n",
    "API Server Integration: This diagram maps the data flow through the FastAPI application. The Unity Client sends a request to /v1/chat. The server invokes the orchestration loop (defined in Section 5), writes redacted audit metadata only, and returns the structured ChatResponse containing text, audio (Base64), and animation cues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b849f99",
   "metadata": {},
   "source": [
    "The complete production FastAPI web server — the HTTP interface that the Unity-based SPARC-P client calls to interact with the AI agents — is defined here. The application object (`app`) and its endpoints are registered; the server does not start serving until `uvicorn.run(app, ...)` is called (which happens in the SLURM launch script).\n",
    "\n",
    "What the server contains:\n",
    "\n",
    "**Configuration & audit logging setup:**\n",
    "- Reads `SPARC_BASE_PATH` and `SPARC_AUDIT_LOG` from environment variables, defaulting to `/blue/`.\n",
    "- Calls `validate_audit_log_path()` at startup to ensure the log directory exists and is writable — failing loudly if not, so audit compliance issues are caught before the first API call.\n",
    "- `log_redacted_audit_event()` writes only compliant metadata to the audit log: session ID, agent type, whether the message was safe, response latency, and a UTC timestamp. **No transcript text or PHI is written** — this is the HIPAA \"transient PHI\" model.\n",
    "\n",
    "**Request/response models (Pydantic):**\n",
    "- `ChatRequest`: Validates that `session_id` is 1–128 characters of alphanumerics/hyphens/underscores (preventing injection via session IDs) and `user_transcript` is 1–10,000 characters.\n",
    "- `ChatResponse`: The structured response containing the caregiver's text, audio (Base64), animation cues, and coach feedback.\n",
    "\n",
    "**`GET /health`** — Returns service status, whether the orchestrator is ready, and audit retention metadata. Used by monitoring systems to detect if the service is degraded.\n",
    "\n",
    "**`POST /v1/chat`** — The primary endpoint:\n",
    "1. Validates the request schema\n",
    "2. Calls `app_graph.ainvoke()` with the transcript and timing context\n",
    "3. Logs a redacted audit event\n",
    "4. Returns the `ChatResponse` with caregiver text, audio, cues, and feedback\n",
    "\n",
    "> **Thread safety note:** `app_graph` is set to `None` if `build_app_graph()` fails at startup. The `/v1/chat` endpoint checks for this and returns HTTP 503 (Service Unavailable) immediately, preventing any request from reaching an uninitialized orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# 6.1 Configuration & Logging\n",
    "BASE_PATH = os.environ.get(\"SPARC_BASE_PATH\", \"/blue/jasondeanarnold/SPARCP\")\n",
    "LOG_FILE = os.environ.get(\"SPARC_AUDIT_LOG\", os.path.join(BASE_PATH, \"logs\", \"audit.log\"))\n",
    "AUDIT_RETENTION_DAYS = int(os.environ.get(\"SPARC_AUDIT_RETENTION_DAYS\", \"30\"))\n",
    "LOG_DIR = os.path.dirname(LOG_FILE) or \".\"\n",
    "\n",
    "def validate_audit_log_path(log_file: str) -> None:\n",
    "    log_dir = os.path.dirname(log_file) or \".\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    if not os.access(log_dir, os.W_OK):\n",
    "        raise PermissionError(f\"Audit log directory is not writable: {log_dir}\")\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\"):\n",
    "        pass\n",
    "\n",
    "validate_audit_log_path(LOG_FILE)\n",
    "logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "app_graph = None\n",
    "\n",
    "\n",
    "def log_redacted_audit_event(session_id: str, agent_type: str, is_safe: bool, latency_ms: float):\n",
    "    event = {\n",
    "        \"event\": \"chat_turn\",\n",
    "        \"event_ts\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"session_id\": session_id,\n",
    "        \"agent_type\": agent_type,\n",
    "        \"is_safe\": is_safe,\n",
    "        \"latency_ms\": round(latency_ms, 2),\n",
    "        \"retention_days\": AUDIT_RETENTION_DAYS,\n",
    "    }\n",
    "    logging.info(json.dumps(event, sort_keys=True))\n",
    "\n",
    "\n",
    "def initialize_orchestrator():\n",
    "    \"\"\"Build and inject the orchestrator graph once at startup/init time.\"\"\"\n",
    "    global app_graph\n",
    "    try:\n",
    "        app_graph = build_app_graph()\n",
    "    except Exception as exc:\n",
    "        app_graph = None\n",
    "        logging.error(f\"Failed to initialize orchestrator graph: {exc}\")\n",
    "\n",
    "initialize_orchestrator()\n",
    "\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    session_id: str = Field(..., min_length=1, max_length=128, pattern=r\"^[a-zA-Z0-9_-]+$\")\n",
    "    user_transcript: str = Field(..., min_length=1, max_length=10000)\n",
    "\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    caregiver_text: str\n",
    "    caregiver_audio_b64: str\n",
    "    caregiver_animation_cues: dict\n",
    "    coach_feedback: str\n",
    "\n",
    "\n",
    "# 6.2 Endpoints\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    orchestrator_ready = app_graph is not None and hasattr(app_graph, \"ainvoke\")\n",
    "    return {\n",
    "        \"status\": \"ok\" if orchestrator_ready else \"degraded\",\n",
    "        \"service\": \"SPARC-P Backend\",\n",
    "        \"orchestrator_ready\": orchestrator_ready,\n",
    "        \"audit_log_path\": LOG_FILE,\n",
    "        \"audit_retention_days\": AUDIT_RETENTION_DAYS,\n",
    "    }\n",
    "\n",
    "\n",
    "@app.post(\"/v1/chat\", response_model=ChatResponse)\n",
    "async def chat_endpoint(request: ChatRequest):\n",
    "    # Fail-fast for uninitialized orchestration\n",
    "    if app_graph is None or not hasattr(app_graph, \"ainvoke\"):\n",
    "        raise HTTPException(status_code=503, detail=\"Orchestrator is not initialized\")\n",
    "\n",
    "    # Invoke orchestrator\n",
    "    start_time = time.perf_counter()\n",
    "    initial_state = {\n",
    "        \"transcript\": request.user_transcript,\n",
    "        \"history\": [],\n",
    "        \"feedback\": \"\",\n",
    "        \"next_action\": \"\",\n",
    "        \"final_response\": {},\n",
    "    }\n",
    "    result = await app_graph.ainvoke(initial_state)\n",
    "    latency_ms = (time.perf_counter() - start_time) * 1000\n",
    "\n",
    "    response_data = result.get(\"final_response\", {})\n",
    "    caregiver_text = response_data.get(\"text\", \"Error\")\n",
    "\n",
    "    # Redacted audit log only (no raw transcript / PHI content)\n",
    "    safety_result = result.get(\"safety\", {})\n",
    "    is_safe = bool(safety_result.get(\"is_safe\", False))\n",
    "    log_redacted_audit_event(\n",
    "        session_id=request.session_id,\n",
    "        agent_type=\"orchestrator\",\n",
    "        is_safe=is_safe,\n",
    "        latency_ms=latency_ms,\n",
    "    )\n",
    "\n",
    "    return ChatResponse(\n",
    "        caregiver_text=caregiver_text,\n",
    "        caregiver_audio_b64=response_data.get(\"audio\", \"\"),\n",
    "        caregiver_animation_cues=response_data.get(\"cues\", {}),\n",
    "        coach_feedback=result.get(\"feedback\", \"\"),\n",
    "    )\n",
    "\n",
    "# To run:\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e3410",
   "metadata": {},
   "source": [
    "Three automated smoke tests run against the FastAPI application using `TestClient` — a built-in FastAPI/Starlette utility that sends HTTP requests to the app in-memory without needing a running server. All three tests run immediately.\n",
    "\n",
    "**Test A — Health endpoint:**\n",
    "- Sends `GET /health` and prints the response. Expected: `{\"status\": \"ok\", \"orchestrator_ready\": true, ...}` if the orchestrator initialized successfully.\n",
    "\n",
    "**Test B — Successful chat request:**\n",
    "- Sends a valid `POST /v1/chat` request with a proper `session_id` and an on-topic HPV vaccine question.\n",
    "- Expected: HTTP 200 with a `ChatResponse` JSON body containing `caregiver_text`, `coach_feedback`, etc.\n",
    "\n",
    "**Test C — Degraded service (orchestrator unavailable):**\n",
    "- Saves the current `app_graph`, sets it to `None` to simulate a startup failure, sends the same chat request, then restores `app_graph`.\n",
    "- Expected: HTTP 503 with a `\"Orchestrator is not initialized\"` detail message.\n",
    "- **Restores `app_graph` afterward** so subsequent cells still work correctly.\n",
    "\n",
    "> **If Test B fails with 503 when it should pass:** The orchestrator failed to initialize (likely because NeMo Guardrails couldn't load its config files). Check that `create_rails_config()` was run first (Section 3.2) and that the guardrails directory path is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4effd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Orchestrator Smoke Tests (FastAPI TestClient)\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "# A) Health endpoint should reflect orchestrator readiness\n",
    "health = client.get(\"/health\")\n",
    "print(\"Health:\", health.status_code, health.json())\n",
    "\n",
    "# B) Chat endpoint should succeed when orchestrator is initialized\n",
    "ok_payload = {\"session_id\": \"smoke-session\", \"user_transcript\": \"Can you help me talk about HPV vaccines?\"}\n",
    "ok_response = client.post(\"/v1/chat\", json=ok_payload)\n",
    "print(\"Chat (ready):\", ok_response.status_code, ok_response.json())\n",
    "\n",
    "# C) Chat endpoint should fail-fast when orchestrator is unavailable\n",
    "saved_graph = app_graph\n",
    "app_graph = None\n",
    "degraded_response = client.post(\"/v1/chat\", json=ok_payload)\n",
    "print(\"Chat (degraded):\", degraded_response.status_code, degraded_response.json())\n",
    "\n",
    "# Restore state for subsequent cells\n",
    "app_graph = saved_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ca417",
   "metadata": {},
   "source": [
    "This is the **H10 guardrails regression check** — it reads the companion markdown file (`3_SPARC_RIVA_Backend.md`) and verifies that the critical NeMo Guardrails integration code patterns are documented there, and that a specific dangerous legacy pattern (keyword-only safety checking) is not present.\n",
    "\n",
    "What it checks:\n",
    "- **7 required markers** must be present in the documentation, including the NeMo import line, the `SPARC_GUARDRAILS_DIR` environment variable name, the `RailsConfig.from_path()` call, and the `enforce_output` method. These verify that the full runtime guardrails path (not a shortcut) is implemented and documented.\n",
    "- **2 blocked patterns** must NOT appear:\n",
    "  - `is_safe = \"politics\" not in text.lower()` — a fragile keyword-based safety check from an earlier version. This approach was replaced by NeMo Guardrails because keyword matching is trivially circumvented (e.g., \"pol1tics\") and doesn't understand context.\n",
    "  - A commented-out NeMo import — which would indicate the guardrails code was disabled rather than removed.\n",
    "\n",
    "> **Why this check exists:** Earlier versions of this notebook used simple keyword matching for safety. This regression check ensures that if someone edits the notebook and reverts to the simpler approach for debugging, the CI-style assertion will block them from committing that regression to documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac028e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 H10 Guardrails Regression Checks\n",
    "\n",
    "runtime_source = open(\"3_SPARC_RIVA_Backend.md\", \"r\", encoding=\"utf-8\").read()\n",
    "\n",
    "required_guardrails_markers = [\n",
    "    \"from nemoguardrails import LLMRails, RailsConfig\",\n",
    "    \"SPARC_GUARDRAILS_DIR\",\n",
    "    \"os.path.join(base_path, \\\"guardrails\\\")\",\n",
    "    \"RailsConfig.from_path(self.rails_path)\",\n",
    "    \"self.rails = LLMRails(rails_config)\",\n",
    "    \"async def enforce_output\",\n",
    "    \"safety = turn_result.get(\\\"safety\\\"\",\n",
    "]\n",
    "missing_markers = [m for m in required_guardrails_markers if m not in runtime_source]\n",
    "assert not missing_markers, f\"Missing guardrails runtime markers: {missing_markers}\"\n",
    "\n",
    "blocked_legacy_patterns = [\n",
    "    \"is_safe = \\\"politics\\\" not in text.lower()\",\n",
    "    \"# from nemoguardrails import LLMRails, RailsConfig\",\n",
    "]\n",
    "legacy_found = [p for p in blocked_legacy_patterns if p in runtime_source]\n",
    "assert not legacy_found, f\"Legacy keyword-only safety logic still present: {legacy_found}\"\n",
    "\n",
    "print(\"✅ H10/L6 regression checks passed: guardrails runtime path is enforced and CWD-relative guardrails output is removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12089ef",
   "metadata": {},
   "source": [
    "This is the **H14 schema regression check** — it verifies that the `ChatRequest` Pydantic model in the documentation has the correct, security-hardened field constraints (not the older, unconstrained versions).\n",
    "\n",
    "What it checks:\n",
    "- **3 required markers** must be in the documentation: the Pydantic import, the `session_id` field definition with `min_length=1, max_length=128, pattern=r\"^[a-zA-Z0-9_-]+$\"`, and the `user_transcript` field with `max_length=10000`.\n",
    "- **2 blocked patterns** must NOT appear: bare `session_id: str` and bare `user_transcript: str` without validation constraints. These patterns were used in an earlier version of the notebook and represent a security vulnerability — without length limits, a malicious user could send arbitrarily large payloads, and without the regex pattern on `session_id`, SQL injection or path traversal characters could appear in audit log entries.\n",
    "\n",
    "> **Why the `session_id` regex matters:** The session ID appears in audit log entries. If it contained characters like `/`, `..`, or SQL injection strings, a malicious session ID could corrupt audit logs or, in less hardened deployments, enable log injection attacks. The `^[a-zA-Z0-9_-]+$` pattern allows only safe alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d097d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5 H14 Request Schema Regression Checks\n",
    "\n",
    "runtime_source = open(\"3_SPARC_RIVA_Backend.md\", \"r\", encoding=\"utf-8\").read()\n",
    "\n",
    "required_schema_markers = [\n",
    "    \"from pydantic import BaseModel, Field\",\n",
    "    \"session_id: str = Field(..., min_length=1, max_length=128, pattern=r\\\"^[a-zA-Z0-9_-]+$\\\")\",\n",
    "    \"user_transcript: str = Field(..., min_length=1, max_length=10000)\",\n",
    "]\n",
    "missing_markers = [m for m in required_schema_markers if m not in runtime_source]\n",
    "assert not missing_markers, f\"Missing request schema constraint markers: {missing_markers}\"\n",
    "\n",
    "blocked_legacy_patterns = [\n",
    "    \"session_id: str\\n\",\n",
    "    \"user_transcript: str\\n\",\n",
    "]\n",
    "legacy_found = [p for p in blocked_legacy_patterns if p in runtime_source]\n",
    "assert not legacy_found, f\"Legacy unconstrained request fields still present: {legacy_found}\"\n",
    "\n",
    "print(\"✅ H14 regression checks passed: request schema constraints are enforced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94325d84",
   "metadata": {},
   "source": [
    "## 7.0 Security and Compliance\n",
    "**HIPAA Mandate**: This system uses a 'Transient PHI' model. User audio and transcripts are processed in-memory and discarded immediately after the conversational turn. No PHI is written to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab23b24",
   "metadata": {},
   "source": [
    "### 7.1 Production Deployment Script\n",
    "\n",
    "To deploy this backend as a persistent service on HiPerGator, we generate a SLURM script (`launch_backend.slurm`). This script:\n",
    "- Uses your available **4 GPUs and 16 CPU cores** for parallelizable service capacity.\n",
    "- Loads `conda`, `cuda`, and `apptainer`.\n",
    "- Launches Riva + FastAPI backend for persistent service execution.\n",
    "\n",
    "Canonical artifact source policy:\n",
    "- **Source of truth** for executable launch content is the generator function in Notebook 3 (`generate_launch_script`).\n",
    "- Markdown companion content must mirror the canonical launch markers exactly.\n",
    "\n",
    "![notebook 3 - section 7.png](images/notebook_3_-_section_7.png)\n",
    "\n",
    "Security and Compliance: This section outlines the security protocols and persistent deployment. It adheres to the HIPAA Mandate using a 'Transient PHI' model, where user data is processed in-memory and immediately discarded. The launch_backend.slurm script ensures the service runs persistently on a secure GPU node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db950fe1",
   "metadata": {},
   "source": [
    "`launch_backend.slurm` is the SLURM batch script that deploys the complete SPARC-P backend (Riva speech server + FastAPI orchestration server) as a persistent service on HiPerGator.\n",
    "\n",
    "What the generated script does when submitted to the HiPerGator scheduler:\n",
    "1. **Resource allocation**: Requests 4 GPUs, 16 CPU cores, 128 GB RAM, 7-day runtime on the `gpu` partition. The 4 GPUs support the LLM (fine-tuned adapter), Riva ASR model, Riva TTS model, and a spare for burst capacity.\n",
    "2. **Module loading**: Loads `conda`, `cuda/12.8`, and `apptainer` — all three are required for the backend.\n",
    "3. **Conda activation**: Activates the `sparc_backend` environment which contains FastAPI, LangGraph, Riva client, and NeMo Guardrails.\n",
    "4. **Environment verification**: Imports `fastapi`, `langgraph`, and `transformers` to confirm the environment is healthy before the expensive Riva startup begins.\n",
    "5. **Riva server launch (`apptainer exec --nv`)**: Starts the Riva speech AI container in the background (`&`) with GPU access. The `sleep 30` gives Riva time to load its ASR/TTS models (~30 seconds) before the FastAPI app tries to connect.\n",
    "6. **FastAPI backend (`uvicorn main:app --workers 2`)**: Starts the Python backend with 2 worker processes for concurrency. This is a blocking call (no `&`) — when it terminates, the SLURM job exits and Riva is killed.\n",
    "7. **Cleanup**: The `kill $RIVA_PID` command on exit ensures Riva doesn't become an orphaned process.\n",
    "\n",
    "> **To deploy:** Transfer `launch_backend.slurm` to HiPerGator and submit with `sbatch launch_backend.slurm`. Monitor output in `backend_<jobid>.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77803f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 SLURM Launch Script Generator (Conda-based)\n",
    "import os\n",
    "\n",
    "def generate_launch_script():\n",
    "    \"\"\"\n",
    "    Generates a SLURM script for persistent backend deployment using conda.\n",
    "    Resource profile: 4 GPUs and 16 CPU cores for parallelization.\n",
    "    \"\"\"\n",
    "    script_content = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=sparcp-backend\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=${SPARC_SLURM_EMAIL:-YOUR_EMAIL@ufl.edu}\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --qos=jasondeanarnold-b\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=4\n",
    "#SBATCH --gpus-per-task=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=128gb\n",
    "#SBATCH --time=7-00:00:00\n",
    "#SBATCH --output=backend_%j.log\n",
    "#SBATCH --error=backend_%j.err\n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "echo \"=== SPARC-P Backend Service Launch ===\"\n",
    "\n",
    "echo \"Resource profile: 4 GPUs, 16 CPU cores allocated\"\n",
    "\n",
    "# 1. Load required modules\n",
    "module purge\n",
    "module load conda\n",
    "module load cuda/12.8\n",
    "module load apptainer\n",
    "\n",
    "# 2. Resolve runtime paths from environment\n",
    "SPARC_BASE_PATH=${SPARC_BASE_PATH:-/blue/jasondeanarnold/SPARCP}\n",
    "CONDA_ENV=${SPARC_BACKEND_ENV:-$SPARC_BASE_PATH/conda_envs/sparc_backend}\n",
    "RIVA_SIF=${SPARC_RIVA_SIF:-$SPARC_BASE_PATH/containers/riva_server.sif}\n",
    "BACKEND_WORKDIR=${SPARC_BACKEND_WORKDIR:-$SPARC_BASE_PATH/backend}\n",
    "\n",
    "echo \"Using SPARC_BASE_PATH=$SPARC_BASE_PATH\"\n",
    "echo \"Activating conda environment: $CONDA_ENV\"\n",
    "conda activate $CONDA_ENV\n",
    "\n",
    "# 3. Verify environment\n",
    "echo \"Python: $(which python)\"\n",
    "python -c \"import fastapi, langgraph, transformers; print('✓ Backend packages loaded')\"\n",
    "\n",
    "# 4. Launch Riva container in background\n",
    "echo \"Starting Riva server...\"\n",
    "apptainer exec --nv $RIVA_SIF riva_start.sh &\n",
    "RIVA_PID=$!\n",
    "sleep 30  # Wait for Riva to initialize\n",
    "\n",
    "# 5. Start FastAPI backend\n",
    "echo \"Starting FastAPI backend...\"\n",
    "cd $BACKEND_WORKDIR\n",
    "uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2\n",
    "\n",
    "# Cleanup on exit\n",
    "kill $RIVA_PID\n",
    "echo \"Backend service stopped.\"\n",
    "date\n",
    "\"\"\"\n",
    "    with open(\"launch_backend.slurm\", \"w\") as f:\n",
    "        f.write(script_content.strip())\n",
    "    print(\"✓ Generated launch_backend.slurm\")\n",
    "    print(\"\\nIMPORTANT: Update SPARC_SLURM_EMAIL if needed\")\n",
    "    print(\"\\nSubmit with: sbatch launch_backend.slurm\")\n",
    "\n",
    "generate_launch_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab1daf",
   "metadata": {},
   "source": [
    "This is the **H9 markdown drift sync check** — it verifies that the companion documentation file (`3_SPARC_RIVA_Backend.md`) is synchronized with the actual SLURM deployment script generated by the previous cell. It guards against \"documentation drift\" — the common problem where someone updates the code but forgets to update the docs.\n",
    "\n",
    "What it checks by looking for 4 specific strings in the markdown file:\n",
    "- `module load conda` — confirms the conda module loading step is documented\n",
    "- `module load apptainer` — confirms the Apptainer/container step is documented\n",
    "- `apptainer exec --nv $RIVA_SIF riva_start.sh` — confirms the exact Riva launch command is documented (with GPU flag `--nv` and the env variable `$RIVA_SIF`)\n",
    "- `uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2` — confirms the exact FastAPI launch command is documented\n",
    "\n",
    "> **If this check fails:** It means the companion markdown documentation (`3_SPARC_RIVA_Backend.md`) is out of sync with the actual SLURM script. Update the relevant section in the markdown file to match the current launch commands, then re-run this check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e115e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 H9 Sync Check — Markdown Companion Drift Guard\n",
    "\n",
    "def validate_launch_doc_sync(md_path=\"3_SPARC_RIVA_Backend.md\"):\n",
    "    canonical_markers = [\n",
    "        \"module load conda\",\n",
    "        \"module load apptainer\",\n",
    "        \"apptainer exec --nv $RIVA_SIF riva_start.sh\",\n",
    "        \"uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2\",\n",
    "    ]\n",
    "\n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        md_text = f.read()\n",
    "\n",
    "    missing = [marker for marker in canonical_markers if marker not in md_text]\n",
    "    assert not missing, f\"Markdown launch doc drift detected. Missing markers: {missing}\"\n",
    "    print(\"✅ H9 sync check passed: markdown companion contains canonical launch markers.\")\n",
    "\n",
    "validate_launch_doc_sync()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
