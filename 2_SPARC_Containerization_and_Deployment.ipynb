{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9f1e66",
   "metadata": {},
   "source": [
    "# SPARC Containerization and Deployment\n",
    "\n",
    "## 1.0 Introduction\n",
    "This notebook covers the final phase: packaging the SPARC backend into portable containers and deploying them to HiPerGator with a robust networking bridge.\n",
    "\n",
    "**⚠️ Important Note on Conda vs Containers:**\n",
    "Per UF RC best practices, **conda environments are preferred** for HiPerGator and PubApps deployments. Containers (Apptainer/Podman) should only be used when:\n",
    "- You have complex system-level dependencies\n",
    "- You need guaranteed reproducibility across different environments\n",
    "- You're deploying to systems without conda support\n",
    "\n",
    "For most SPARC-P use cases, follow the conda-based workflow in Notebooks 1 and 3.\n",
    "\n",
    "### 1.1 Objectives\n",
    "1. **Containerize**: Create Dockerfiles for the Multi-Agent System (MAS) (optional/reference)\n",
    "2. **Bridge**: Configure the WebSocket-to-gRPC bridge for Unity connectivity\n",
    "3. **Deploy**: Generate production SLURM scripts for HiPerGator\n",
    "\n",
    "### 1.2 Introduction Diagram\n",
    "![Introduction](./images/notebook_2_-_section_1.png)\n",
    "\n",
    "Introduction: This section sets the objectives for packaging and deploying the backend. While containers are covered for completeness, the recommended approach for HiPerGator/PubApps is to use conda environments (see environment_backend.yml) with Podman containers only for Riva speech services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c881ee",
   "metadata": {},
   "source": [
    "## 2.0 Containerization (Docker -> Apptainer)\n",
    "We develop with Docker/Podman and deploy with Apptainer on HPC.\n",
    "\n",
    "\n",
    "![notebook 2 - section 2.png](images/notebook_2_-_section_2.png)\n",
    "\n",
    "\n",
    "Container Build Strategy: This flow shows the Multi-Stage Build strategy used to create secure and small containers. A \"Builder\" stage installs dependencies from `requirements.txt` using `pip`, and then only the necessary artifacts are copied over to a slim \"Runtime\" stage. This excludes compiler tools and cache files from the final production image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3432fa",
   "metadata": {},
   "source": [
    "### 2.1 Dockerfile Definition\n",
    "\n",
    "This script creates a `Dockerfile.mas` for the Multi-Agent System. We uses a multi-stage build strategy:\n",
    "1. **Builder Stage**: Installs dependencies from `requirements.txt` using `pip`.\n",
    "2. **Runtime Stage**: Copies only the installed packages to a lightweight `python:3.11-slim` image. This minimizes the container size and attack surface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a7b91",
   "metadata": {},
   "source": [
    "Two files are created on disk — `requirements.txt` and `Dockerfile.mas` — the building blocks for packaging the SPARC-P backend into a portable container.\n",
    "\n",
    "- `requirements.txt` lists every Python library the backend needs (FastAPI for the web server, bitsandbytes for quantized AI models, Presidio for PII scrubbing, Riva client for speech, etc.) so they can all be installed at once inside the container.\n",
    "- `Dockerfile.mas` is a recipe that tells the container engine exactly how to build the backend image. It uses a **two-stage build**: the first stage (builder) installs all the heavy build tools and packages; the second stage (runtime) copies only the final installed packages into a much smaller, clean image — keeping the deployed container lean and secure.\n",
    "- When you run `create_requirements_file()` and `create_dockerfile()` at the bottom, both files are written to the current directory and a confirmation message is printed.\n",
    "\n",
    "> **Note:** For HiPerGator and PubApps deployments, the preferred approach is conda environments (see `environment_backend.yml`). This Dockerfile is primarily for local development or situations where containers are explicitly required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaecd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Dockerfile for Multi-Agent System (MAS)\n",
    "# NOTE: For HiPerGator training, use conda environments instead (see environment_backend.yml)\n",
    "# This is primarily for local development or when containers are explicitly required\n",
    "\n",
    "import os\n",
    "\n",
    "def create_requirements_file():\n",
    "    \"\"\"Writes canonical pip dependency artifact used by Dockerfile.mas.\"\"\"\n",
    "    requirements = \"\"\"\n",
    "fastapi\n",
    "uvicorn[standard]\n",
    "pydantic>=2.5.0\n",
    "numpy>=1.24.0\n",
    "aiofiles\n",
    "websockets\n",
    "python-multipart\n",
    "transformers>=4.36.0\n",
    "accelerate>=0.25.0\n",
    "tokenizers>=0.15.0\n",
    "bitsandbytes>=0.41.0\n",
    "peft>=0.7.0\n",
    "langchain>=0.1.0\n",
    "langchain-community>=0.0.13\n",
    "langchain-openai>=0.0.5\n",
    "langchain-chroma>=0.1.0\n",
    "langgraph>=0.0.26\n",
    "nvidia-riva-client>=2.14.0\n",
    "nemoguardrails>=0.5.0\n",
    "chromadb>=0.4.22\n",
    "presidio-analyzer>=2.2.33\n",
    "presidio-anonymizer>=2.2.33\n",
    "firebase-admin>=6.2.0\n",
    "python-jose[cryptography]\n",
    "python-dotenv\n",
    "grpcio\n",
    "grpcio-tools\n",
    "\"\"\".strip()\n",
    "    with open(\"requirements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(requirements + \"\\n\")\n",
    "    print(\"Created requirements.txt\")\n",
    "\n",
    "def create_dockerfile():\n",
    "    if not os.path.exists(\"requirements.txt\"):\n",
    "        raise FileNotFoundError(\"requirements.txt not found. Run create_requirements_file() first.\")\n",
    "\n",
    "    dockerfile_content = \"\"\"\n",
    "# --- Build Stage ---\n",
    "FROM python:3.11-slim as builder\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\\\n",
    "    build-essential \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Python dependencies\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "# --- Runtime Stage ---\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "\n",
    "# Install runtime dependencies only\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages\n",
    "COPY --from=builder /app /app\n",
    "\n",
    "EXPOSE 8000\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "    \"\"\"\n",
    "    with open(\"Dockerfile.mas\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(dockerfile_content.strip())\n",
    "    print(\"Created Dockerfile.mas\")\n",
    "    print(\"\\nFor HiPerGator/PubApps deployment, conda environments are preferred.\")\n",
    "    print(\"See environment_backend.yml and setup_conda_env.sh\")\n",
    "\n",
    "create_requirements_file()\n",
    "create_dockerfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725846b0",
   "metadata": {},
   "source": [
    "## 3.0 Local Development with Podman\n",
    "Podman allows creating a 'pod' to simulate the production network namespace.\n",
    "\n",
    "\n",
    "![notebook 2 - section 3.png](images/notebook_2_-_section_3.png)\n",
    "\n",
    "Local Development Pod (Podman): This illustrates the local development environment using Podman Pods. Unlike standard Docker containers which are isolated, a \"Pod\" shares a network namespace (localhost). This allows the Riva Server, WebSocket Bridge, and MAS (Multi-Agent System) to communicate locally, perfectly simulating the production environment on a developer's machine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bfe748",
   "metadata": {},
   "source": [
    "### 3.1 Podman Local Workflow\n",
    "\n",
    "For local development, **Podman** is preferred over Docker because it allows us to create a **Pod**. A Pod shares a network namespace (localhost), allowing the separate containers (Riva, Bridge, MAS) to communicate with each other as if they were running on the same machine, mimicking the production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b21291",
   "metadata": {},
   "source": [
    "A ready-to-use sequence of shell commands for spinning up all three SPARC-P services locally using Podman is printed below. Nothing is executed automatically — copy and paste these commands into your local terminal.\n",
    "\n",
    "Step by step:\n",
    "1. `podman pod create` — creates a shared network sandbox named `sparc-backend`, with port 8080 forwarded so you can reach it from your browser.\n",
    "2. `podman run ... riva-server` — starts the NVIDIA Riva speech AI engine (ASR + TTS) inside the pod.\n",
    "3. `podman run ... ws-bridge` — starts the WebSocket bridge, which relays audio between the browser and Riva, using `localhost:50051` as the Riva address (works because everything is in the same pod).\n",
    "4. `podman run ... mas-server` — starts the Multi-Agent System (the AI orchestration layer) on port 8000.\n",
    "\n",
    "> **Tip:** After running these commands, open your browser to `http://localhost:8080` to interact with the system locally before deploying to HiPerGator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Podman Workflow (Reference Commands)\n",
    "# Run these in your local terminal to test interaction between Riva, Bridge, and MAS.\n",
    "\n",
    "podman_commands = \"\"\"\n",
    "# 1. Create Pod\n",
    "podman pod create --name sparc-backend -p 8080:8080\n",
    "\n",
    "# 2. Run Riva Server\n",
    "podman run -d --pod sparc-backend --name riva-server nvcr.io/nvidia/riva/riva-speech:2.16.0-server\n",
    "\n",
    "# 3. Run WebSocket Bridge\n",
    "podman run -d --pod sparc-backend --name ws-bridge \\\n",
    "    -e RIVA_API_URL=localhost:50051 \\\n",
    "    riva-websocket-bridge:latest\n",
    "\n",
    "# 4. Run MAS Server\n",
    "podman run -d --pod sparc-backend --name mas-server your-repo/mas-server:latest\n",
    "\"\"\"\n",
    "print(podman_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b6c95",
   "metadata": {},
   "source": [
    "## 4.0 Production Deployment on HiPerGator\n",
    "Deploying persistent services using SLURM and Apptainer.\n",
    "\n",
    "\n",
    "![notebook 2 - section 4.png](images/notebook_2_-_section_4.png)\n",
    "\n",
    "Production Deployment (SLURM): This diagram shows the execution flow of the sparc_production.slurm script on HiPerGator. It details how the SLURM scheduler allocates resources (GPUs) and then launches three concurrent Apptainer containers in the background, keeping them alive with a wait command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1876e68",
   "metadata": {},
   "source": [
    "### 4.1 Building SIF Images\n",
    "\n",
    "HiPerGator uses Apptainer, which requires Singularity Image Format (`.sif`) files. The commands below (commented out) show how to convert your local Docker images into SIF files using `apptainer build`. These files should be stored in the `/blue` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd5f76",
   "metadata": {},
   "source": [
    "A placeholder reminder section — it prints an instruction message but does not build anything automatically. The commented-out lines (starting with `#`) show the actual Apptainer commands you would run in a HiPerGator terminal to convert your Docker images into `.sif` files.\n",
    "\n",
    "Why this step is needed: HiPerGator's production compute nodes use **Apptainer** (formerly Singularity) instead of Docker or Podman. Apptainer requires images in `.sif` (Singularity Image Format) format. The `apptainer build` command reads from a locally running Docker daemon and writes a portable `.sif` file that can be stored in your `/blue` project directory and run on any HiPerGator node.\n",
    "\n",
    "> **To actually use this:** Uncomment the three `apptainer build` lines, load the apptainer module (`module load apptainer`), and run them in a HiPerGator login node terminal — not in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Build SIF Images\n",
    "# !module load apptainer\n",
    "# !apptainer build mas_server.sif docker-daemon://your-repo/mas-server:latest\n",
    "# !apptainer build websocket_bridge.sif docker-daemon://riva-websocket-bridge:latest\n",
    "print(\"Build SIF images from Docker/Daemon sources before deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa7b5f",
   "metadata": {},
   "source": [
    "### 4.2 Production Service Launch\n",
    "\n",
    "This function generates the `sparc_production.slurm` script. This is the critical deployment artifact that runs the system on HiPerGator. Key features:\n",
    "- **Persistent GPUs**: Requests 4 GPUs on the AI partition.\n",
    "- **Background Processes**: Launches Riva, the Bridge, and the MAS server as background tasks (`&`).\n",
    "- **Wait Command**: The `wait` instruction keeps the SLURM job alive indefinitely, ensuring the services remain running.\n",
    "- **Policy-Compliant Runtime**: Uses a finite default (`7-00:00:00`) to avoid scheduler rejection; only use `UNLIMITED` if your partition/QoS explicitly allows it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f4243",
   "metadata": {},
   "source": [
    "`sparc_production.slurm` is a SLURM job script that, when submitted to HiPerGator, starts all three SPARC-P services as a persistent long-running job.\n",
    "\n",
    "Key details of the generated script:\n",
    "- **Resource request:** 3 tasks × 1 GPU each (so the 3 services can each use a dedicated GPU), 4 CPU cores and 96 GB RAM total, on the `gpu` partition under the project QoS.\n",
    "- **7-day time limit:** The job runs for up to 7 days before the scheduler terminates it. Re-submit weekly to keep the service alive.\n",
    "- **Background launches (`&`):** Each service (Riva, WebSocket bridge, MAS) is started as a background process so they all run concurrently. A 20-second sleep between Riva and the bridge gives Riva time to initialize before downstream services connect.\n",
    "- **`wait` command:** This keeps the SLURM job alive until all background processes finish (or the time limit is hit). Without it, the job would exit immediately after launching the services.\n",
    "- **Environment variables:** Paths to the `.sif` files are read from environment variables with safe defaults pointing to `/blue/jasondeanarnold/SPARCP/containers/`.\n",
    "\n",
    "> **To deploy:** Transfer `sparc_production.slurm` to HiPerGator and submit with `sbatch sparc_production.slurm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8102953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Production Deployment Script (Persistent Service)\n",
    "# Note: Containers are optional; conda-based deployment is preferred for HiPerGator/PubApps\n",
    "\n",
    "def generate_production_script():\n",
    "    script_content = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=sparcp-service\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --qos=jasondeanarnold-b\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=3\n",
    "#SBATCH --gpus-per-task=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=96gb\n",
    "#SBATCH --time=7-00:00:00\n",
    "#SBATCH --output=sparc_service_%j.log\n",
    "\n",
    "module purge\n",
    "module load apptainer\n",
    "\n",
    "SPARC_BASE_PATH=${SPARC_BASE_PATH:-/blue/jasondeanarnold/SPARCP}\n",
    "SPARC_BIND_ROOT=${SPARC_BIND_ROOT:-/blue}\n",
    "RIVA_SIF=${SPARC_RIVA_SIF:-$SPARC_BASE_PATH/containers/riva_server.sif}\n",
    "BRIDGE_SIF=${SPARC_BRIDGE_SIF:-$SPARC_BASE_PATH/containers/websocket_bridge.sif}\n",
    "MAS_SIF=${SPARC_MAS_SIF:-$SPARC_BASE_PATH/containers/mas_server.sif}\n",
    "\n",
    "# Launch Services in Background\n",
    "echo \"Starting Riva...\"\n",
    "apptainer exec --nv ${RIVA_SIF} riva_start.sh &\n",
    "sleep 20\n",
    "\n",
    "echo \"Starting Bridge...\"\n",
    "apptainer exec ${BRIDGE_SIF} riva-websocket-gateway --riva-uri=localhost:50051 --port=8080 &\n",
    "\n",
    "echo \"Starting MAS...\"\n",
    "apptainer exec --nv -B $SPARC_BIND_ROOT ${MAS_SIF} uvicorn main:app --host 0.0.0.0 --port 8000 &\n",
    "\n",
    "wait\n",
    "\"\"\"\n",
    "    with open(\"sparc_production.slurm\", \"w\") as f:\n",
    "        f.write(script_content.strip())\n",
    "    print(\"Generated sparc_production.slurm\")\n",
    "    print(\"\\nNote: For most use cases, prefer conda-based deployment from Notebook 3\")\n",
    "    print(\"Policy note: Use UNLIMITED only when explicitly allowed by your partition/QoS\")\n",
    "\n",
    "generate_production_script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
