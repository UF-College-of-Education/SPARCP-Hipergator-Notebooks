{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARC Containerization and Deployment\n",
    "\n",
    "## 1.0 Introduction\n",
    "This notebook covers the final phase: packaging the SPARC backend into portable containers and deploying them to HiPerGator with a robust networking bridge.\n",
    "\n",
    "**⚠️ Important Note on Conda vs Containers:**\n",
    "Per UF RC best practices, **conda environments are preferred** for HiPerGator and PubApps deployments. Containers (Apptainer/Podman) should only be used when:\n",
    "- You have complex system-level dependencies\n",
    "- You need guaranteed reproducibility across different environments\n",
    "- You're deploying to systems without conda support\n",
    "\n",
    "For most SPARC-P use cases, follow the conda-based workflow in Notebooks 1 and 3.\n",
    "\n",
    "### 1.1 Objectives\n",
    "1. **Containerize**: Create Dockerfiles for the Multi-Agent System (MAS) (optional/reference)\n",
    "2. **Bridge**: Configure the WebSocket-to-gRPC bridge for Unity connectivity\n",
    "3. **Deploy**: Generate production SLURM scripts for HiPerGator\n",
    "\n",
    "### 1.2 Introduction Diagram\n",
    "![Introduction](./images/notebook_2_-_section_1.png)\n",
    "\n",
    "Introduction: This section sets the objectives for packaging and deploying the backend. While containers are covered for completeness, the recommended approach for HiPerGator/PubApps is to use conda environments (see environment_backend.yml) with Podman containers only for Riva speech services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c881ee",
   "metadata": {},
   "source": [
    "## 2.0 Containerization (Docker -> Apptainer)\n",
    "We develop with Docker/Podman and deploy with Apptainer on HPC.\n",
    "\n",
    "\n",
    "![notebook 2 - section 2.png](images/notebook_2_-_section_2.png)\n",
    "\n",
    "\n",
    "Container Build Strategy: This flow shows the Multi-Stage Build strategy used to create secure and small containers. A \"Builder\" stage installs dependencies from `requirements.txt` using `pip`, and then only the necessary artifacts are copied over to a slim \"Runtime\" stage. This excludes compiler tools and cache files from the final production image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3432fa",
   "metadata": {},
   "source": [
    "### 2.1 Dockerfile Definition\n",
    "\n",
    "This script creates a `Dockerfile.mas` for the Multi-Agent System. We uses a multi-stage build strategy:\n",
    "1. **Builder Stage**: Installs dependencies from `requirements.txt` using `pip`.\n",
    "2. **Runtime Stage**: Copies only the installed packages to a lightweight `python:3.10-slim` image. This minimizes the container size and attack surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Dockerfile for Multi-Agent System (MAS)\n",
    "# NOTE: For HiPerGator training, use conda environments instead (see environment_backend.yml)\n",
    "# This is primarily for local development or when containers are explicitly required\n",
    "\n",
    "import os\n",
    "\n",
    "def create_requirements_file():\n",
    "    \"\"\"Writes canonical pip dependency artifact used by Dockerfile.mas.\"\"\"\n",
    "    requirements = \"\"\"\n",
    "fastapi\n",
    "uvicorn[standard]\n",
    "pydantic>=2.5.0\n",
    "numpy>=1.24.0\n",
    "aiofiles\n",
    "websockets\n",
    "python-multipart\n",
    "transformers>=4.36.0\n",
    "accelerate>=0.25.0\n",
    "tokenizers>=0.15.0\n",
    "bitsandbytes>=0.41.0\n",
    "peft>=0.7.0\n",
    "langchain>=0.1.0\n",
    "langchain-community>=0.0.13\n",
    "langchain-openai>=0.0.5\n",
    "langchain-chroma>=0.1.0\n",
    "langgraph>=0.0.26\n",
    "nvidia-riva-client>=2.14.0\n",
    "nemoguardrails>=0.5.0\n",
    "chromadb>=0.4.22\n",
    "presidio-analyzer>=2.2.33\n",
    "presidio-anonymizer>=2.2.33\n",
    "firebase-admin>=6.2.0\n",
    "python-jose[cryptography]\n",
    "python-dotenv\n",
    "grpcio\n",
    "grpcio-tools\n",
    "\"\"\".strip()\n",
    "    with open(\"requirements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(requirements + \"\\n\")\n",
    "    print(\"Created requirements.txt\")\n",
    "\n",
    "def create_dockerfile():\n",
    "    if not os.path.exists(\"requirements.txt\"):\n",
    "        raise FileNotFoundError(\"requirements.txt not found. Run create_requirements_file() first.\")\n",
    "\n",
    "    dockerfile_content = \"\"\"\n",
    "# --- Build Stage ---\n",
    "FROM python:3.11-slim as builder\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\\\n",
    "    build-essential \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Python dependencies\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "# --- Runtime Stage ---\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "\n",
    "# Install runtime dependencies only\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages\n",
    "COPY --from=builder /app /app\n",
    "\n",
    "EXPOSE 8000\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "    \"\"\"\n",
    "    with open(\"Dockerfile.mas\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(dockerfile_content.strip())\n",
    "    print(\"Created Dockerfile.mas\")\n",
    "    print(\"\\nFor HiPerGator/PubApps deployment, conda environments are preferred.\")\n",
    "    print(\"See environment_backend.yml and setup_conda_env.sh\")\n",
    "\n",
    "create_requirements_file()\n",
    "create_dockerfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Local Development with Podman\n",
    "Podman allows creating a 'pod' to simulate the production network namespace.\n",
    "\n",
    "\n",
    "![notebook 2 - section 3.png](images/notebook_2_-_section_3.png)\n",
    "\n",
    "Local Development Pod (Podman): This illustrates the local development environment using Podman Pods. Unlike standard Docker containers which are isolated, a \"Pod\" shares a network namespace (localhost). This allows the Riva Server, WebSocket Bridge, and MAS (Multi-Agent System) to communicate locally, perfectly simulating the production environment on a developer's machine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Podman Local Workflow\n",
    "\n",
    "For local development, **Podman** is preferred over Docker because it allows us to create a **Pod**. A Pod shares a network namespace (localhost), allowing the separate containers (Riva, Bridge, MAS) to communicate with each other as if they were running on the same machine, mimicking the production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Podman Workflow (Reference Commands)\n",
    "# Run these in your local terminal to test interaction between Riva, Bridge, and MAS.\n",
    "\n",
    "podman_commands = \"\"\"\n",
    "# 1. Create Pod\n",
    "podman pod create --name sparc-backend -p 8080:8080\n",
    "\n",
    "# 2. Run Riva Server\n",
    "podman run -d --pod sparc-backend --name riva-server nvcr.io/nvidia/riva/riva-speech:2.16.0-server\n",
    "\n",
    "# 3. Run WebSocket Bridge\n",
    "podman run -d --pod sparc-backend --name ws-bridge \\\n",
    "    -e RIVA_API_URL=localhost:50051 \\\n",
    "    riva-websocket-bridge:latest\n",
    "\n",
    "# 4. Run MAS Server\n",
    "podman run -d --pod sparc-backend --name mas-server your-repo/mas-server:latest\n",
    "\"\"\"\n",
    "print(podman_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Production Deployment on HiPerGator\n",
    "Deploying persistent services using SLURM and Apptainer.\n",
    "\n",
    "\n",
    "![notebook 2 - section 4.png](images/notebook_2_-_section_4.png)\n",
    "\n",
    "Production Deployment (SLURM): This diagram shows the execution flow of the sparc_production.slurm script on HiPerGator. It details how the SLURM scheduler allocates resources (GPUs) and then launches three concurrent Apptainer containers in the background, keeping them alive with a wait command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Building SIF Images\n",
    "\n",
    "HiPerGator uses Apptainer, which requires Singularity Image Format (`.sif`) files. The commands below (commented out) show how to convert your local Docker images into SIF files using `apptainer build`. These files should be stored in the `/blue` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Build SIF Images\n",
    "# !module load apptainer\n",
    "# !apptainer build mas_server.sif docker-daemon://your-repo/mas-server:latest\n",
    "# !apptainer build websocket_bridge.sif docker-daemon://riva-websocket-bridge:latest\n",
    "print(\"Build SIF images from Docker/Daemon sources before deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Production Service Launch\n",
    "\n",
    "This function generates the `sparc_production.slurm` script. This is the critical deployment artifact that runs the system on HiPerGator. Key features:\n",
    "- **Persistent GPUs**: Requests 4 GPUs on the AI partition.\n",
    "- **Background Processes**: Launches Riva, the Bridge, and the MAS server as background tasks (`&`).\n",
    "- **Wait Command**: The `wait` instruction keeps the SLURM job alive indefinitely, ensuring the services remain running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Production Deployment Script (Persistent Service)\n",
    "# Note: Containers are optional; conda-based deployment is preferred for HiPerGator/PubApps\n",
    "\n",
    "def generate_production_script():\n",
    "    script_content = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=sparcp-service\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --qos=jasondeanarnold-b\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=3\n",
    "#SBATCH --gpus-per-task=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=96gb\n",
    "#SBATCH --time=UNLIMITED\n",
    "#SBATCH --output=sparc_service_%j.log\n",
    "\n",
    "module purge\n",
    "module load apptainer\n",
    "\n",
    "SPARC_BASE_PATH=${SPARC_BASE_PATH:-/blue/jasondeanarnold/SPARCP}\n",
    "SPARC_BIND_ROOT=${SPARC_BIND_ROOT:-/blue}\n",
    "RIVA_SIF=${SPARC_RIVA_SIF:-$SPARC_BASE_PATH/containers/riva_server.sif}\n",
    "BRIDGE_SIF=${SPARC_BRIDGE_SIF:-$SPARC_BASE_PATH/containers/websocket_bridge.sif}\n",
    "MAS_SIF=${SPARC_MAS_SIF:-$SPARC_BASE_PATH/containers/mas_server.sif}\n",
    "\n",
    "# Launch Services in Background\n",
    "echo \"Starting Riva...\"\n",
    "apptainer exec --nv ${RIVA_SIF} riva_start.sh &\n",
    "sleep 20\n",
    "\n",
    "echo \"Starting Bridge...\"\n",
    "apptainer exec ${BRIDGE_SIF} riva-websocket-gateway --riva-uri=localhost:50051 --port=8080 &\n",
    "\n",
    "echo \"Starting MAS...\"\n",
    "apptainer exec --nv -B $SPARC_BIND_ROOT ${MAS_SIF} uvicorn main:app --host 0.0.0.0 --port 8000 &\n",
    "\n",
    "wait\n",
    "\"\"\"\n",
    "    with open(\"sparc_production.slurm\", \"w\") as f:\n",
    "        f.write(script_content.strip())\n",
    "    print(\"Generated sparc_production.slurm\")\n",
    "    print(\"\\nNote: For most use cases, prefer conda-based deployment from Notebook 3\")\n",
    "\n",
    "generate_production_script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
